# **√âcole Nationale de Commerce et de Gestion (ENCG) - 4√®me Ann√©e**

# **Projet : Analyse de Donn√©es et Mod√©lisation pour la Pr√©diction Automobile**

## **Introduction G√©n√©rale**

Dans ce document, nous pr√©sentons une analyse compl√®te d'un jeu de
donn√©es automobile et le processus de pr√©paration des donn√©es en vue de
construire un mod√®le de Machine Learning. Ce travail s'inscrit dans un
th√®me g√©n√©ral d'**analyse pr√©dictive**, o√π nous transformons des donn√©es
brutes en informations utilisables par un mod√®le.

L'objectif de l'analyse est de comprendre les caract√©ristiques du
dataset, traiter les donn√©es manquantes, encoder les variables
cat√©gorielles, explorer la distribution des variables, puis pr√©parer le
tout pour la mod√©lisation.

## **Sommaire D√©taill√©**

1.  **Introduction g√©n√©rale** -- Pr√©sentation du th√®me et du contexte
2.  **Description du notebook** -- Structure et objectifs
3.  **Analyse et pr√©paration des donn√©es**
    -   Chargement du dataset\
    -   Nettoyage et traitement des valeurs manquantes\
    -   Encodage des variables cat√©gorielles\
    -   Analyse exploratoire : distributions, corr√©lations\
4.  **Explication d√©taill√©e de chaque cellule de code**\
5.  **Conclusion** -- Synth√®se de l'analyse et implications

## **Description du Notebook**

Le notebook contient une succession de cellules de code et de texte
visant √† pr√©parer les donn√©es √©tape par √©tape. Chaque cellule est
reproduite ci‚Äëdessous accompagn√©e d'une explication compl√®te.

## **Explications D√©taill√©es des Cellules**

### üíª Cellule de Code 1

``` python
#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#For ignoring warning
import warnings
warnings.filterwarnings("ignore")
```

#### üß† Explication du code

Ce bloc de code me permet d‚Äôimporter les biblioth√®ques essentielles dont j‚Äôai besoin pour r√©aliser mon analyse de donn√©es automobile.

pandas (pd) : j‚Äôutilise cette biblioth√®que pour charger mon dataset et manipuler mes donn√©es (par exemple les caract√©ristiques des voitures).

numpy (np) : elle me sert √† effectuer des calculs num√©riques n√©cessaires lors de la pr√©paration de mes donn√©es.

matplotlib (plt) et seaborn (sns) : je m‚Äôen sers pour cr√©er des visualisations afin d‚Äôexplorer mon dataset, analyser mes variables, comprendre les tendances et identifier des relations entre les caract√©ristiques automobiles.

warnings.filterwarnings("ignore") : j‚Äôutilise cette instruction pour masquer les avertissements non importants et garder mon notebook clair et lisible.

Ainsi, ce bloc initialise mon environnement d‚Äôanalyse, indispensable pour la pr√©paration de mes donn√©es et la construction de mon futur mod√®le de pr√©diction automobile.

### üíª Cellule de Code 2

``` python
df=pd.read_csv('/content/drive/MyDrive/Analyse_PayGapEurope/car_price_dataset_medium.csv')
df
```

#### üß† Explication du code

J‚Äôutilise pd.read_csv() pour charger mon fichier contenant les donn√©es automobiles.
La variable df devient mon tableau principal, et l‚Äôafficher me permet de voir imm√©diatement la structure et le contenu de mon dataset.

### üíª Cellule de Code 3

``` python
df.shape
```

#### üß† Explication du code

J‚Äôutilise df.shape pour conna√Ætre le nombre de lignes et de colonnes dans mon dataset.

### üíª Cellule de Code 4

``` python
#Checking for Duplicates
df.duplicated().sum()
```

#### üß† Explication du code

J‚Äôutilise cette commande pour compter combien de lignes sont dupliqu√©es dans mon dataset.

### üíª Cellule de Code 5

``` python
#Removing Duplicates
df=df.drop_duplicates()
```

#### üß† Explication du code

J‚Äôutilise drop_duplicates() pour supprimer toutes les lignes r√©p√©t√©es dans mon dataset.

### üíª Cellule de Code 6

``` python
#Checking for null values
df.isnull().sum()
```

#### üß† Explication du code

J‚Äôutilise cette commande pour compter le nombre de valeurs manquantes dans chaque colonne de mon dataset.

### üíª Cellule de Code 7

``` python
df.info()
```

#### üß† Explication du code

J‚Äôutilise df.info() pour obtenir un r√©sum√© complet de mon dataset :

le nombre de lignes,

le nombre de colonnes,

le type de chaque variable,

la pr√©sence ou non de valeurs manquantes.

### üíª Cellule de Code 8

``` python
df.describe()
```

#### üß† Explication du code

J‚Äôutilise df.describe() pour obtenir les statistiques principales de mes variables num√©riques : moyenne, minimum, maximum, √©cart-type, quartiles‚Ä¶

### üíª Cellule de Code 9

``` python
from sklearn import preprocessing
le = preprocessing.LabelEncoder()

df['Brand'] = le.fit_transform(df['Brand'])
df['Fuel_Type'] = le.fit_transform(df['Fuel_Type'])
df['Transmission'] = le.fit_transform(df['Transmission'])
df['Owner_Type'] = le.fit_transform(df['Owner_Type'])
```

#### üß† Explication du code

Cette partie encode les variables cat√©gorielles en valeurs num√©riques
pour permettre leur utilisation par un mod√®le.

### üíª Cellule de Code 10

``` python
#Let's check what's happened now
df
```

#### üß† Explication du code

Cette cellule contribue au flux g√©n√©ral d'analyse ou de pr√©paration des
donn√©es.

### üíª Cellule de Code 11

``` python
df.info()
```

#### üß† Explication du code

Cette cellule contribue au flux g√©n√©ral d'analyse ou de pr√©paration des
donn√©es.

### üíª Cellule de Code 12

``` python
# Let's check the distribution of Target variable.
# Using histplot because Price_USD is numerical
plt.figure(figsize=(10, 6))
sns.histplot(df['Price_USD'], kde=True)
plt.title('Target Distribution (Price_USD)')
plt.show()
```

#### üß† Explication du code

Afin d'√©valuer la r√©partition de ma variable cible (Price_USD), j'ai g√©n√©r√© un histogramme compl√©t√© par une estimation de densit√© (KDE) en utilisant la librairie Seaborn. Cette visualisation graphique est essentielle pour que je puisse identifier la forme de ma distribution (sym√©trique, asym√©trique) et d√©tecter la pr√©sence √©ventuelle de valeurs aberrantes, informations qui influenceront mes choix de pr√©traitement et de mod√©lisation.

<img src="G1.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 13

``` python
# Define your threshold
price_limit = 60000

# Count values greater than the limit
expensive_cars = df[df['Price_USD'] > price_limit].shape[0]

# Count values less than the limit
cheaper_cars = df[df['Price_USD'] < price_limit].shape[0]

print(f"Cars with Price > {price_limit}: {expensive_cars}")
print(f"Cars with Price < {price_limit}: {cheaper_cars}")
```

#### üß† Explication du code

J'ai souhait√© effectuer une analyse de l'asym√©trie de ma variable cible en d√©finissant un seuil de prix √† 60 000 USD. Cette d√©marche m'a permis de distinguer clairement les v√©hicules consid√©r√©s comme co√ªteux de ceux qui sont plus abordables dans mon jeu de donn√©es.

### üíª Cellule de Code 14

``` python
# function for plotting
def plot(col, df=df):
    return df.groupby(col)['Price_USD'].mean().plot(kind='bar', figsize=(8,5), ylabel='Average Price USD')
```

#### üß† Explication du code

J'ai cr√©√© ma propre fonction Python nomm√©e plot dans le but d'automatiser et de simplifier mes analyses de donn√©es exploratoires (EDA). Cette fonction me permet de regrouper mes donn√©es par n'importe quelle colonne cat√©gorielle sp√©cifi√©e (col) et de calculer la moyenne du prix en USD (Price_USD) pour chaque cat√©gorie. En retournant directement un diagramme √† barres, ma fonction me fait gagner du temps en visualisant instantan√©ment l'impact de chaque caract√©ristique (marque, couleur, type de moteur, etc.) sur le prix moyen des v√©hicules.

### üíª Cellule de Code 15

``` python
plot('Brand')
plt.title('Average Price by Brand')
plt.show()
```

#### üß† Explication du code

J'ai imm√©diatement utilis√© ma fonction personnalis√©e plot pour r√©aliser une analyse rapide de l'impact de la marque sur le prix moyen. En appelant plot('Brand'), je demande √† mon syst√®me de calculer et d'afficher le prix moyen en USD pour chaque marque de voiture pr√©sente dans mon jeu de donn√©es.

<img src="G2.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 16

``` python
plot('Model_Year')
plt.title('Average Price by Model_Year')
plt.show()
```

#### üß† Explication du code

En r√©utilisant ma fonction plot, j'ai sp√©cifiquement analys√© la relation entre le prix moyen du v√©hicule et son ann√©e de mod√®le (Model_Year). Ce graphique me permet d'observer l'√©volution du prix des voitures en fonction de leur anciennet√©.

<img src="G3.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 17

``` python
plot('Fuel_Type')
plt.title('Average Price by Fuel_Type')
plt.show()
```

#### üß† Explication du code

J'ai poursuivi mon analyse exploratoire en utilisant √† nouveau ma fonction plot pour examiner l'influence du type de carburant (Fuel_Type) sur le prix moyen des v√©hicules. L'affichage de ce diagramme √† barres est important car il met en lumi√®re les diff√©rences de valeur entre les voitures fonctionnant √† l'essence, au diesel, ou avec des carburants alternatifs (comme l'√©lectrique ou l'hybride).

<img src="G4.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 18

``` python
plot('Transmission')
plt.title('Average Price by Transmission')
plt.show()
```

#### üß† Explication du code

J'ai cibl√© la variable type de transmission (Transmission) dans ma derni√®re analyse avec ma fonction plot. Ce graphique √† barres me permet de comparer le prix moyen des v√©hicules √©quip√©s d'une transmission automatique par rapport √† ceux ayant une transmission manuelle.

<img src="G5.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 19

``` python
# We split power into 3 groups: Low (<200), Medium (200-400), High (>400)
bins = [0, 200, 400, 1000]
labels = ['Low Power', 'Medium Power', 'High Power']
df['Power_Category'] = pd.cut(df['Max_Power_bhp'], bins=bins, labels=labels)

plot('Power_Category')
plt.title('Average Price by Power Category')
plt.show()
```

#### üß† Explication du code

J'ai effectu√© une √©tape de cat√©gorisation sur ma variable continue Max_Power_bhp (puissance maximale), car cette transformation facilite l'analyse et la mod√©lisation. J'ai d√©fini trois groupes de puissance (Faible, Moyenne, √âlev√©e) en utilisant des bornes (bins) sp√©cifiques. J'ai ensuite appliqu√© ma fonction plot sur cette nouvelle variable cat√©gorielle (Power_Category).

<img src="G6.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 20

``` python
plot('Seats')
plt.title('Average Price by number of Seats')
plt.show()
```

#### üß† Explication du code

En utilisant ma fonction plot, j'ai cibl√© la variable Seats pour analyser son effet sur le prix moyen.

<img src="G7.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 21

``` python
# We split Kilometers_Driven into 3 groups: Low (<200), Medium (200-400), High (>400)
bins = [0, 20000, 40000, 100000]
labels = ['Low KM', 'Medium KM', 'High KM']
df['Kilometers_Category'] = pd.cut(df['Kilometers_Driven'], bins=bins, labels=labels)

plot('Kilometers_Category')
plt.title('Average Price by Kilometers_Driven')
plt.show()
```

#### üß† Explication du code

Apr√®s avoir analys√© la puissance, j'ai proc√©d√© √† la cat√©gorisation de la variable continue Kilometers_Driven (kilom√®tres parcourus). J'ai cr√©√© trois groupes (Faible, Moyen, √âlev√©) en d√©finissant de nouvelles bornes (bins) adapt√©es √† mon jeu de donn√©es pour mieux segmenter l'usure des v√©hicules. En appliquant ma fonction plot √† cette nouvelle variable cat√©gorielle, je peux visualiser clairement comment le niveau de kilom√©trage influence de mani√®re inversement proportionnelle le prix moyen. Cette √©tape est fondamentale pour confirmer l'impact de l'usure sur la d√©pr√©ciation.

<img src="G8.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 22

``` python
# Dropping columns with the weakest correlation to Price_USD
df_new = df.drop(columns=['Car_ID', 'Brand', 'Transmission', 'Fuel_Type'])
df_new
```

#### üß† Explication du code

J'ai entam√© la phase de pr√©paration de mes donn√©es pour la mod√©lisation en d√©cidant de supprimer certaines colonnes de mon jeu de donn√©es initial. J'ai choisi d'√©liminer Car_ID, Brand, Transmission, et Fuel_Type car, selon mon analyse de corr√©lation et mes graphiques exploratoires pr√©c√©dents, ces variables pr√©sentaient la plus faible corr√©lation ou le moins de valeur ajout√©e pour la pr√©diction du Price_USD.

### üíª Cellule de Code 23

``` python
#Finding Correlation
# Drop the categorical columns that are not suitable for direct numerical correlation calculation
df_numerical_corr = df_new.drop(columns=['Power_Category', 'Kilometers_Category'])
cn=df_numerical_corr.corr()
cn
```

#### üß† Explication du code

Pour avancer dans mon analyse, j'ai calcul√© la matrice de corr√©lation entre toutes les variables num√©riques restantes de mon jeu de donn√©es (df_new). J'ai d'abord supprim√© les colonnes Power_Category et Kilometers_Category car elles sont cat√©gorielles et non adapt√©es au calcul direct du coefficient de corr√©lation de Pearson que j'utilise.

### üíª Cellule de Code 24

``` python
#Correlation
cmap=sns.diverging_palette(260,-10,s=50, l=75, n=6,
as_cmap=True)
plt.subplots(figsize=(18,18))
sns.heatmap(cn,cmap=cmap,annot=True, square=True)
plt.show()
```

#### üß† Explication du code

Pour pr√©senter les r√©sultats de mon analyse de corr√©lation de fa√ßon claire et intuitive, j'ai g√©n√©r√© une carte de chaleur (heatmap) √† l'aide de Seaborn. J'ai utilis√© ma matrice de corr√©lation (cn) comme donn√©e source. Ce graphique est essentiel car il me permet de visualiser imm√©diatement l'intensit√© des corr√©lations :

Les couleurs claires/rouges indiquent une corr√©lation positive forte (les deux variables augmentent ensemble).

Les couleurs fonc√©es/bleues indiquent une corr√©lation n√©gative forte (l'une augmente quand l'autre diminue).

De plus, la fonction annot=True m'a permis d'afficher les valeurs num√©riques pr√©cises des coefficients de corr√©lation sur chaque cellule, ce qui est crucial pour la validation quantitative de mes hypoth√®ses avant la mod√©lisation.

<img src="G9.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 25

``` python
kot = cn[cn>=.40]
plt.figure(figsize=(12,8))
sns.heatmap(kot, cmap="Purples")
```

#### üß† Explication du code

Apr√®s avoir g√©n√©r√© ma carte de chaleur compl√®te, j'ai voulu me concentrer uniquement sur les corr√©lations les plus fortes. J'ai donc cr√©√© un nouvel objet, kot, qui isole dans ma matrice de corr√©lation (cn) toutes les paires de variables pr√©sentant un coefficient de corr√©lation sup√©rieur ou √©gal √† 0,40 (en valeur absolue). J'ai ensuite visualis√© ce sous-ensemble dans une seconde carte de chaleur plus √©pur√©e. Cette d√©marche est cruciale car elle me permet de mettre en √©vidence les facteurs les plus d√©terminants pour la pr√©diction du prix, facilitant ainsi la s√©lection finale des variables d'entr√©e pour mon mod√®le d'apprentissage automatique.

<img src="G10.png" alt="Alt Text" width="1000" height="600" style="display: block; margin: 0 auto;">

### üíª Cellule de Code 26

``` python
df_new['Mileage_Year_Interaction'] = df_new['Mileage_kmpl'] * df_new['Model_Year']
df_new
```

#### üß† Explication du code

J'ai proc√©d√© √† la cr√©ation d'une nouvelle variable d'interaction nomm√©e Mileage_Year_Interaction. Cette √©tape d'ing√©nierie de caract√©ristiques (Feature Engineering) est cruciale. Elle consiste √† multiplier le kilom√©trage par litre (Mileage_kmpl) par l'ann√©e du mod√®le (Model_Year). Mon intention est de capturer une relation non-lin√©aire entre l'efficacit√© du carburant et l'√¢ge de la voiture.

### üíª Cellule de Code 27

``` python
# Splitting independent (X) and dependent (y) variables
X = df_new.drop('Price_USD', axis=1)
y = df_new['Price_USD']
```

#### üß† Explication du code

J'ai maintenant proc√©d√© √† l'√©tape fondamentale de la s√©paration de mes variables. J'ai d√©sign√© la colonne Price_USD comme ma variable d√©pendante (y), c'est-√†-dire la valeur que je cherche √† pr√©dire. Toutes les autres colonnes restantes dans mon DataFrame (df_new) ‚Äî incluant celles que j'ai s√©lectionn√©es et la nouvelle variable d'interaction ‚Äî constituent mes variables ind√©pendantes (X), qui sont les caract√©ristiques que mon mod√®le utilisera pour faire cette pr√©diction. Cette distinction est cruciale pour l'entra√Ænement de tout algorithme d'apprentissage supervis√©.

### üíª Cellule de Code 28

``` python
# ADASYN is for classification tasks to handle imbalanced classes.
# Since 'Price_USD' is a continuous target variable for a regression problem, ADASYN is not applicable.
# If you were performing a classification task (e.g., classifying cars as 'cheap', 'medium', 'expensive'),
# you would first need to convert 'Price_USD' into discrete categories before using ADASYN.
```

#### üß† Explication du code

Ce commentaire est une note critique que j'ai ins√©r√©e pour justifier mon approche. J'y explique que je n'ai pas eu recours √† la technique de sur√©chantillonnage ADASYN (ou √† toute autre m√©thode similaire) parce que mon projet est une t√¢che de r√©gression ‚Äî je pr√©dis une valeur continue (Price_USD).

### üíª Cellule de Code 29

``` python
len(X)
```

#### üß† Explication du code

Cette cellule contribue au flux g√©n√©ral d'analyse ou de pr√©paration des
donn√©es.

### üíª Cellule de Code 30

``` python
#Splitting data for training and testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.25, random_state=0)
```

#### üß† Explication du code

Cette √©tape s√©pare les donn√©es en ensembles d'entra√Ænement et de test
pour √©valuer un mod√®le.

### üíª Cellule de Code 31

``` python
# One-hot encode the categorical columns 'Power_Category' and 'Kilometers_Category'
X_train_encoded = pd.get_dummies(X_train, columns=['Power_Category', 'Kilometers_Category'], drop_first=True)
X_test_encoded = pd.get_dummies(X_test, columns=['Power_Category', 'Kilometers_Category'], drop_first=True)

# Ensure all columns are aligned between training and testing sets after encoding
X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)

# For regression problems, use a regression model, not LogisticRegression
from sklearn.linear_model import LinearRegression
regression_model = LinearRegression()

# Fit the regression model with the numerically encoded data
regression_model.fit(X_train_encoded, y_train)
```

### üíª Cellule de Code 32

``` python
#Predicting result using testing data with the preprocessed test set
y_lr_pred= regression_model.predict(X_test_encoded)
y_lr_pred
```

### üíª Cellule de Code 33

``` python
# Model accuracy - using regression metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_test, y_lr_pred)
mse = mean_squared_error(y_test, y_lr_pred)
rmse = np.sqrt(mse) # Root Mean Squared Error
r2 = r2_score(y_test, y_lr_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")
```

#### üß† Explication du code 31/32/33

J'ai abord√© l'√©tape cruciale de la mod√©lisation par R√©gression Lin√©aire, en commen√ßant par le pr√©traitement des variables cat√©gorielles.

Encodage (One-Hot Encoding) : J'ai utilis√© pd.get_dummies() sur mes variables cat√©gorielles (Power_Category et Kilometers_Category) pour les convertir en un format num√©rique compr√©hensible par mon mod√®le. J'ai veill√© √† utiliser drop_first=True pour √©viter la multicolin√©arit√©.

Alignement des Jeux de Donn√©es : J'ai align√© mes jeux d'entra√Ænement et de test (X_train_encoded et X_test_encoded) pour m'assurer qu'ils poss√®dent exactement les m√™mes colonnes apr√®s l'encodage, remplissant les valeurs manquantes par 0 si n√©cessaire.

Entra√Ænement du Mod√®le : J'ai ensuite s√©lectionn√© et entra√Æn√© mon mod√®le de R√©gression Lin√©aire (LinearRegression) sur mes donn√©es d'entra√Ænement encod√©es.

Pr√©diction et √âvaluation : J'ai utilis√© le mod√®le entra√Æn√© pour effectuer des pr√©dictions (y_lr_pred) sur le jeu de test. Enfin, j'ai √©valu√© la performance de ce mod√®le en calculant les m√©triques cl√©s de r√©gression :

L'Erreur Absolue Moyenne (MAE) et l'Erreur Quadratique Moyenne (MSE/RMSE) mesurent l'√©cart moyen entre mes pr√©dictions et les vrais prix.

Le coefficient R-carr√© (R2), ma m√©trique principale, indique la proportion de la variance du prix que mon mod√®le parvient √† expliquer. Un R2 proche de 1 signifie que mon mod√®le est tr√®s performant.

### üíª Cellule de Code 34

``` python
# One-hot encode the categorical columns 'Power_Category' and 'Kilometers_Category'
X_train_encoded_dt = pd.get_dummies(X_train, columns=['Power_Category', 'Kilometers_Category'], drop_first=True)
X_test_encoded_dt = pd.get_dummies(X_test, columns=['Power_Category', 'Kilometers_Category'], drop_first=True)

# Ensure all columns are aligned between training and testing sets after encoding
X_train_encoded_dt, X_test_encoded_dt = X_train_encoded_dt.align(X_test_encoded_dt, join='left', axis=1, fill_value=0)

# Use DecisionTreeRegressor for regression problems
from sklearn.tree import DecisionTreeRegressor
dt_model = DecisionTreeRegressor(random_state=0)

# Fit the regression model with the numerically encoded data
dt_model.fit(X_train_encoded_dt, y_train)
```


### üíª Cellule de Code 35

``` python
#Predicting result using testing data
y_dt_pred= dt_model.predict(X_test_encoded_dt)
y_dt_pred
```


### üíª Cellule de Code 36

``` python
# Model accuracy - using regression metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_test, y_dt_pred)
mse = mean_squared_error(y_test, y_dt_pred)
rmse = np.sqrt(mse) # Root Mean Squared Error
r2 = r2_score(y_test, y_dt_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")
```

#### üß† Explication du code 34/35/36

J'ai appliqu√© la m√™me m√©thodologie de pr√©traitement que pr√©c√©demment : j'ai effectu√© l'encodage binaire (pd.get_dummies) de mes variables cat√©gorielles (Power_Category et Kilometers_Category) et j'ai veill√© √† l'alignement strict des colonnes entre mes jeux d'entra√Ænement et de test.

Choix du Mod√®le : J'ai ensuite s√©lectionn√© le mod√®le DecisionTreeRegressor pour explorer les relations non-lin√©aires dans mes donn√©es. L'arbre de d√©cision me permet de segmenter mes donn√©es en fonction de r√®gles simples et d'√©viter les hypoth√®ses de lin√©arit√©.

Entra√Ænement et √âvaluation : J'ai entra√Æn√© le mod√®le (dt_model.fit) et j'ai g√©n√©r√© les pr√©dictions (y_dt_pred). J'ai calcul√© les m√™mes m√©triques (MAE, RMSE, R2) afin que je puisse comparer directement la performance de cet Arbre de D√©cision avec celle de mon mod√®le de R√©gression Lin√©aire et d√©terminer lequel est le plus adapt√© √† la pr√©diction des prix de voitures.

### üíª Cellule de Code 37

``` python
#Fitting K-NN regressor to the training set
from sklearn.neighbors import KNeighborsRegressor
# Use X_train_encoded_dt (or X_train_encoded) which has categorical columns one-hot encoded
knn_model= KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train_encoded_dt, y_train)
```



### üíª Cellule de Code 38

``` python
#Predicting result using testing data
y_knn_pred= knn_model.predict(X_test_encoded_dt)
y_knn_pred
```


### üíª Cellule de Code 39

``` python
# Model accuracy - using regression metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_test, y_knn_pred)
mse = mean_squared_error(y_test, y_knn_pred)
rmse = np.sqrt(mse) # Root Mean Squared Error
r2 = r2_score(y_test, y_knn_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (R2): {r2:.2f}")
```

#### üß† Explication du code 37/38/39

J'ai compl√©t√© ma s√©rie de mod√©lisations en entra√Ænant un mod√®le de R√©gression K-plus-proches voisins (K-NN).

Pr√©paration : J'ai r√©utilis√© les jeux de donn√©es d'entra√Ænement et de test qui ont d√©j√† √©t√© pr√©par√©s et encod√©s (X_train_encoded_dt, X_test_encoded_dt), assurant la coh√©rence avec mes mod√®les pr√©c√©dents.

Mod√®le K-NN : J'ai s√©lectionn√© mon mod√®le K-NN avec un param√®tre de 5 voisins (n_neighbors=5). Ce mod√®le pr√©dit le prix d'une voiture en se basant sur la moyenne des prix de ses cinq voitures les plus similaires dans l'espace des caract√©ristiques.

√âvaluation : Apr√®s l'entra√Ænement et la pr√©diction (y_knn_pred), j'ai calcul√© les m√™mes m√©triques d'√©valuation (MAE, RMSE, R2). La performance de ce mod√®le non-param√©trique est cruciale, car elle me permet de comparer l'efficacit√© d'une approche bas√©e sur la similitude locale avec les approches globales (R√©gression Lin√©aire) et bas√©es sur des r√®gles (Arbre de D√©cision). Le R2 final me donne la derni√®re information n√©cessaire pour s√©lectionner le mod√®le optimal pour la pr√©diction des prix.

### üíª Cellule de Code 40

``` python
# K-Fold Cross Validation

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor

k = 3
kf = KFold(n_splits=k, shuffle=True, random_state=42)

# One-hot encode the categorical columns for cross-validation
X_cv_encoded = pd.get_dummies(X, columns=['Power_Category', 'Kilometers_Category'], drop_first=True)

# Linear Regression model
lr_scores = cross_val_score(LinearRegression(), X_cv_encoded, y, cv=kf, scoring='r2')

# Decision tree model
dt_scores = cross_val_score(DecisionTreeRegressor(random_state=0), X_cv_encoded, y, cv=kf, scoring='r2')

# KNN model
knn_scores = cross_val_score(KNeighborsRegressor(n_neighbors=5), X_cv_encoded, y, cv=kf, scoring='r2')

print("Linear Regression models' average R2 score:", np.mean(lr_scores))
print("Decision tree models' average R2 score:", np.mean(dt_scores))
print("KNN models' average R2 score:", np.mean(knn_scores))
```

#### üß† Explication du code

J'ai conclu ma phase de mod√©lisation en utilisant la technique robuste de la validation crois√©e K-Fold pour obtenir une √©valuation plus fiable et moins biais√©e de la performance de mes mod√®les.Pr√©paration : J'ai initialis√© l'objet KFold avec $k=3$ plis (n_splits=3), ce qui signifie que je divise mon jeu de donn√©es en trois segments, entra√Ænant et testant chacun mon mod√®le trois fois. J'ai √©galement r√©-encod√© mes variables cat√©gorielles (X_cv_encoded) sur l'ensemble complet des donn√©es (X) avant la validation crois√©e.√âvaluation : J'ai ensuite appliqu√© la fonction cross_val_score pour √©valuer mes trois mod√®les (R√©gression Lin√©aire, Arbre de D√©cision et KNN) sur ces trois plis, en utilisant le score R2 comme m√©trique d'√©valuation.R√©sultats : J'ai calcul√© et affich√© la moyenne des scores R2 pour chaque mod√®le. Cette moyenne repr√©sente la performance g√©n√©ralis√©e de chaque algorithme. C'est le r√©sultat final qui me permet de d√©terminer quel mod√®le est le plus performant pour pr√©dire les prix des v√©hicules et de justifier mon choix final dans le compte rendu.

## **Conclusion**

Nous avons restructur√© et expliqu√© de mani√®re d√©taill√©e votre notebook
d'analyse automobile. Chaque √©tape de pr√©paration des donn√©es a √©t√©
explicit√©e pour permettre une meilleure compr√©hension du processus. Ce
document est d√©sormais pr√™t √† √™tre utilis√© comme support de cours,
rapport ou documentation professionnelle.
